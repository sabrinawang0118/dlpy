{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection to viya\n",
    "\n",
    "viya_conn=swat.CAS('your viya host.com',5570, 'username', 'password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlpy.transformers import bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: CREATE BERT CLASSIFICATION MODEL\n",
    "Note the viya_conn variable. This is the SWAT connection to the active Viya session referred\n",
    "to earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = 'cache_dir' #can be relative or absolute path. here the relative path is used. \n",
    "bert = bert_model.BERT_Model(viya_conn,\n",
    "cache_dir,\n",
    "'bert-base-uncased',\n",
    "2,\n",
    "num_hidden_layers=12,\n",
    "max_seq_len=256,\n",
    "verbose=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: PREPARE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "reviews = pd.read_csv('data/Reviews.csv', header=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a numeric value to indicate positive or negative sentiment for each review.\n",
    "Filter out the neutral reviews (3 stars), and then assign a negative label to 1- and 2-star reviews and a\n",
    "positive label to 4- and 5-star reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_idx = reviews[\"Score\"] != 3\n",
    "inputs = reviews[t_idx][\"Text\"].to_list()\n",
    "targets = reviews[t_idx][\"Score\"].to_list()\n",
    "for ii,val in enumerate(targets):\n",
    " inputs[ii] = inputs[ii].replace(\"<br />\",\"\")\n",
    " if (val == 1) or (val == 2): # negative reviews\n",
    "     targets[ii] = 1\n",
    " elif (val == 4) or (val == 5): # positive reviews\n",
    "     targets[ii] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, import the data preparation helper function. Invoking the helper function tokenizes\n",
    "the review data and creates the three input values (token, position, segment) associated\n",
    "with each token as well as the sentiment target for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlpy.transformers.bert_utils import bert_prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tgt_var, train, test = bert_prepare_data(viya_conn,\n",
    " bert.get_tokenizer(),\n",
    " input_a=inputs,\n",
    " target=targets,\n",
    " train_fraction=0.8,\n",
    " segment_vocab_size=bert.get_segment_size(),\n",
    " classification_problem=bert.get_problem_type(),\n",
    "#  truncation=True,\n",
    " max_seq_len= 512,\n",
    " verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: CREATE SAS VIYA BERT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third step is to create a SAS Deep Learning model that is the equivalent of the base\n",
    "BERT model plus a classification (fully connected) layer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.compile(num_target_var=num_tgt_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: ATTACH MODEL PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth step is to attach the trained model parameters stored in the HDF5 file to the\n",
    "BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.load_weights('cache_dir/bert-base-uncased.kerasmodel.h5', num_target_var=num_tgt_var, freeze_base_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: FINE-TUNE BERT CLASSIFICATION MODEL\n",
    "\n",
    "Perform fine-tuning training. \n",
    "When the fit() function finishes executing, your BERT model is fine-tuned for sentiment\n",
    "analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.set_optimizer_parameters(learning_rate=2e-5)\n",
    "bert.fit(train,\n",
    " data_specs= bert.get_data_spec(num_tgt_var),\n",
    " optimizer=bert.get_optimizer(),\n",
    " text_parms=bert.get_text_parameters(),\n",
    " seed=12345,\n",
    " n_threads=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL EVALUATION\n",
    "\n",
    "You can now evaluate your fine-tuned sentiment analysis model by using the test data set.\n",
    "Use the predict() function exposed by the DLPy BERT model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = bert.predict(test,\n",
    " text_parms=bert.get_text_parameters())\n",
    "print(res['ScoreInfo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
